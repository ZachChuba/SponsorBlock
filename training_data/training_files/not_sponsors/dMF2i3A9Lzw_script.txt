you are watching TV hi welcome to another ColdFusion video ten years ago the word fake would normally be associated with plastic surgery or cheap DVDs but as the world moved more and more online and anyone anywhere can create and publish a story or an image we often have to ask is this fake in this episode we'll take an interesting look at the rise of deep fakes is the kind of technology that could potentially save hundreds of thousands of dollars but also has some real-world consequences let's dive in but first I audiobook with a 30 day trial membership just head on to www.nasa.gov the acne logo on it it was put on digitally and it can be removed just as easily drops of water can be put in the space left by the erase logo by simply picking up existing drops of water and duplicating them a few centimeters away the potential for the system goes a lot further than that operators say they can take a group photograph for instance and rearrange the people's heads on different shoulders in such perfect detail it would be impossible to tell a change had been made it makes you wonder a picture may still be worth a thousand words but what about that old saying the camera never lies video however remains sacred if you have someone on video then you have the perfect backup for any quote idea or action that you want to attribute to that person but this is all about to change thanks to the rise of deep fakes so what are deep fakes deeper fakes are altered videos usually a famous people produced by newer networks it could be superimposing a face onto a body so it looks like they're doing something that they never did well you can take some speech and then alter the content making the face movements match the new audio that you've put in even before deep fakes you've probably seen the basic system at work it's what powers those goofy snapchat filters where you can have the googly eyes or a demon face the tech behind this face detection is not exactly a new technology even old digital cameras had this feature in 2001 Paul viola and Michael Jones proposed a real-time face detection system now known as the viola Jones object detection framework basically this framework allows machines to easily detect faces by using the differences in brightness between pixels today we still use this basic premise but there are many new steps that have been added together they combine to create computer vision the viola Jones part is used for high level detection of the basic markers of a face but snapchat trained their system on many hundreds of faces that were manually marked with points to show the borders of lips eyes nose and face the trained application can then take a point mask and shift it to match your individual face based on the data that it's getting from your camera at 24 frames per second this is also you can keep those dog ears in place or do that Facebook snapchat technology was mostly built on the experience gained by a Ukrainian company luxury in 2015 and it cost them one hundred and fifty million dollars to acquire so in three short years things have advanced rapidly we know that film studios have been able to swap faces for years Oliver Reed did it for some scenes in Gladiator and a young Carrie Fisher appeared again in Star Wars rogue one but for these the process is long and expensive here's how they did it for the grand moff tarkin character in Star Wars the process we would take - to create a show like this the first thing we do is we shoot the live-action play photography this is with guy Henry as I perform on set and he's dressed in full costume he has what we call a head mounted camera rig which is designed solely for capturing his facial performances of charm this is the earliest test is the first time we ever saw guys motion transferred onto guys model and then put on to Tarkan's first like an early like this the problem is Cushing's performance and Henry's performance didn't always match that required painstaking sometimes frame by frame adjustments constantly refining the most subtle details you can imagine this method took 18 months and would've cost a small fortune and in just my opinion the results are within the realm of a video game cutscene today though free apps like fake app make CGI face mapping a simple tool that almost anyone can operate to drive this point home here's a side by side video comparison of Princess Leia in rogue one one sequences painstakingly made at a cost likely in the hundreds of thousands with the use of an insanely expensive computer the other one was done in 30 minutes by an average guy on an average computer for free yes there's obviously differences but honestly are those differences worth hundreds of thousands of dollars the previous scene was done with a program called fake app and here's how it works so you want to swap the face of Lois Lane in the Superman film with the face of Nicolas Cage the first step is to select your source video then find a whole range of images of Amy Adams who acted Lois Lane and also a whole range of images of Nicolas Cage all of these images together serve as the AIS training data you don't even have to manually download the images one by one the app has an automatic script that downloads all the images at once for you the second step is to get rid of the parts of the images that we don't want like objects in the scene when this is done it's easier for face detection the third step is just to let the AI do its magic a neural network model gets to work learning how to recreate a given face from the images it has here's a snapshot example from within faker the first six columns show face a being transformed into face B and vice versa and the last six columns within each group of three images the leftmost is the original image the middle image is the model trying to redraw the original image and the rightmost is the predicted transformation the network then outputs the score detailing the amount of error there is within the transformations when the score is sufficiently low congratulations you have a good quality deep fate now it's possible to map one face onto another face in real-time video using just images a video is just a collection of rapidly changing images at around 24 to 30 times a second so this makes sense when you think about it technology like this cuts down the cost and effort by many orders of magnitude putting powerful tools in the hands of the everyday person but what about the negatives unsurprisingly there's been a lot of fake adult content created or existing porn scenes have celebrity faces imposed all you need to do is find an actress with a similar build and then most of the work has done for you by the algorithms the adult sector was one of the biggest driving forces behind the recent surge of fake videos however arguably the biggest danger we face is in politics politicians are on camera a lot often in quite a fixed position like standing at a podium or sitting for an interview this makes them incredibly easy subjects for deep fakes all you need to do is record any actor making the facial movements you want and then you could map these onto a politician altering the way they react or even what they say and you might be thinking so you'll still need a really good impersonator to match the voice well well not for long at an Adobe conference in 2016 zu Jin introduced voco this tool was basically Photoshop for audio he uses a learning algorithm to analyse the speech patterns and convert it into text with just 40 minutes of speech it will have examples of almost every sound of that voice in that language so to recreate the new vocal audio or to do is type we can just type the word dogs here and and I kiss my wife and my dogs [Music] here's more his more we can actually type something that's not here so let's remove the word my here and also just type the word Jordan and I kiss Jordan my dog's we're not just going to do with words we can actually type small phrases so let's say okay so we remove those words and we do three time and play back and I kissed Orton three times [Applause] recently researchers at the University of Washington managed to convincingly make Obama say anything the AI managed to actually specifically learn how Obama's mouth moved the heart of our method is a recurrent neural network that transforms input audio to a time-varying mouth shape now most of us don't get our health care through the marketplace to get it through our job or through Medicare or Medicaid then we synthesize mouth texture and what you should know is that thanks to the Affordable Care Act your coverage is better today than it was before next we enhance details and teeth I'll have free preventive care there are no more annual or lifetime limits on essential health care finally we blend the mouth texture onto a retimed target video and match the pose women can get free checkups and you can't get charged more just for being a woman young people can stay on a parent's plan until they turn 26 and the infrastructure that creates good new jobs not to mention the job training that helps folks earn new skills but we can't even create an Obama video from voice impressionists here we go President Barack Obama when you giving a speech make sure you use a lot of pauses and speak at a very weird tammer up and down down and up so thinking about it if you can make a politician say anything you want think about the impact that this could have so in a broader sense if these videos become commonplace perhaps if you give some ground for politicians to actually deny something that they actually said and then it becomes a question of how to even trust any evidence given and this leads us to our final question how do you prove that a video is real it's extremely difficult if you can get a fake video in the raw format that it was uploaded in there are telltale signs that you can find every digital recording device has its own unique algorithms that decide what information is kept you can't store every pixel of every frame it's just too much data so cameras bashed little groups together if they're very close in color for example and this acts as a sort of fingerprint for the camera model so an expert will be able to tell where this has been altered but the thing is once this video has been uploaded and downloaded a few times it's hard enough to find in the first place but it'll be almost impossible once it's traveled around the internet sometimes they'll be telltale glitches when a face moves in a slightly strange way or if 3d mask doesn't exactly match up with the movements of the head but the software will keep getting better making mistakes harder to find so is there any hope well yes there's a couple of things that may save us in the future for example we can rely on AI to fight AI that is an AI that specifically been built to detect fakes let's walk through this idea if an AI is given a training set of fake and real videos and is told which one's a fake and which ones are real perhaps after enough training you'll be able to tell fake videos with better accuracy than we can another solution could be verified videos stored in a blockchain so that they can't be altered and also we'll know that they're real when they're taken from a particular block in the blockchain so that's kind of where we stand right now with great power comes great responsibility and deep fakes has a highly positive side but as you can see there's a negative side as well so I'm going to pass the question on to you guys what are your thoughts on deep fakes let me know in the comments section below I can kind of see the maturity level of a comment section dropping already but anyway this is Ben - gogo you've been watching cold fusion if you just stumbled across this channel feel free to subscribe I'll see you again soon for the next video Jia's guys have a good one [Music] cold be thinking you 