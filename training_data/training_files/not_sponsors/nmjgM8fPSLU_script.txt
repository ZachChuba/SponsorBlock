The film Ex Machina opens on a simple premise; a programmer named Caleb is invited to the private mountain retreat of the visionary CEO Nathan to take part in a Turing Test. Do you what the Turing Test is? It’s when a human interacts with a computer. And if the human doesn’t know they’re
interacting with a computer, the test is passed. What follows is essentially an exploration
of consciousness in a non-human being, one that, based on the many discussions it inspired
afterwards, left the audience wondering whether left the audience wondering whether or not the subject in question was truly conscious. That is to say, whether or not it had the
same level of consciousness that we do. Do you have a name? Yes. Ava. However, I think that this discussion is focused
on the wrong question, and that the real implications of Ex Machina’s Turing Test are somewhat obscured because of it. Let’s first address some of the basics of
scientific inquiry. Regardless of what is being examined, scientists always operate based on a certain  research paradigm; a set of common beliefs and agreements on how problems should be understood and addressed. A research paradigm consists of three elements;
ontology, epistemology, and methodology; each signifying three distinctive questions 
that need to be answered; What is reality? What can we know about it? 
And how we do attain that knowledge? Translating this to the story of Ex Machina, we can distinguish the ontological question about the nature of Ava’s consciousness, the epistemological question about the extent to which Caleb can get access to that consciousness, and the methodological question about the means to get that access, in this case; a Turing Test. Why don’t we start with you telling me something
about yourself? What would you like to know? You can probably tell that most discussions
are centered around the ontological question; did Nathan succeed in creating 
a conscious machine? Was Ava truly conscious? Or was she merely successful 
at pretending to be? A program that mimics all the observable qualities
of consciousness without really possessing it? But I think the discussion becomes much more
interesting when we take into account the epistemological question about the extent to which we can really know and understand consciousness, and the subsequent questions
of methodology. After Caleb’s first sessions with Ava, he too seems to be acknowledge the importance of discussing the process of examination, rather than the outcome. I’m still trying to figure the examination format. It feels like testing Ava through conversation
is kind of a closed loop. It's a closed loop?
- Yeah. Like testing a chess computer 
by only playing chess. You can play it to find out if it makes good moves, but… but that won't tell you if it knows 
that it's playing chess. And it won't tell you if it knows what chess is. It describes the so-called hard problem 
of consciousness; the problem that beneath everything we can observe about it, there is a deeper essence; a fundamentally private and subjective self-experience which cannot be confirmed from the outside. As in, how do you know if a machine is expressing
a real emotion or just simulating one? Does Ava actually like you? Or not? Michael Graziano, the author of 
Rethinking Consciousness, distinguishes between I consciousness and 
M consciousness, to illustrate this distinction. I for information, M for mysterious. Here's how I consciousness works: He explains I consciousness as the mechanistic part; the part that processes information, that relays inputs to outputs, 
and that is observable in the brain. It is also this part that we can pretty successfully
build artificially, as Nathan did with Ava. Are you a good person? Yeah, I think so. I consciousness however, does not account
for the subjective experience of these mechanisms; for that mysterious, seemingly non-materialistic
part of our consciousness; the ghost in the machine, so to say. And the funny thing is, as Graziano points out, 
in our everyday experience, it doesn’t seem to matter all that much as our relation
to the consciousness of others, be they human or non-human, is rarely based on deliberate intellectual considerations, and much more so on automatic intuition; When I talk to another person, I have an automatic impression of thoughts, and emotions and awareness emanating from that person. Of course, that's not the person's real mind, that's my brain generating a handy model of a mind 
and projecting it onto the person. Answer me this. How do you feel about her? Nothing analytical, just, how do you feel? I feel that she’s fucking amazing. Over the course of the sessions 
between Caleb and Ava, we see how extremely potent this gut feeling is 
in making us believe that another being possesses consciousness, and how the real driving forces behind this belief have
little to do with analytical reason. Are you attracted to me? What?
- Are you attracted to me? Did you give her sexuality
as a diversion tactic? I don't follow. Like a stage magician with a hot assistent. So a hot robot who clouds your ability to
judge her AI? Exactly, so, did you program her to flirt
with me? It is because of this that Graziano argues that we, being so easily entranced by anything that gives the impression of consciousness, are actually the least reliable observers on this point. Did you program her to like me, or not? I programmed her to be heterosexual, just
like you were programmed to be heterosexual. Nobody programmed me to be straight.
- You decided to be straight? Please! Of course you were programmed, 
by nature or nurture or both and to be honest, Caleb, you're starting to annoy me now because this is your insecurity talking, this is not your intellect. There’s another element that complicates
our effort to understand consciousness. For as I discussed in my video on exploring
consciousness in film, this inclination to attribute consciousness based on intuition is also heavily affected by a bias towards humanity, meaning that we tend to approach consciousness with the assumption that it is distinctively human. As a result, when we interact with non-human beings, we are less likely to judge them based on the actual attributes of consciousness they exhibit, and more likely based on how much they resemble human behavior. This, I think, stems from the many religious traditions in which consciousness is directly linked to spiritual concepts of the soul, which we of course have claimed 
as unique to ourselves. And seeing as souls are often related to a
divine creator or higher form of consciousness, this would also explain the allure 
to create one ourselves. If you’ve created a conscious machine, 
it’s not the history of man. That’s the history of gods. Even in more secular worldviews, the belief in human consciousness as some special trait that separates us from the rest of nature, and that all other forms of intelligence have to live up to in order to be considered conscious, still lingers. It is why, in reaction to the earlier mentioned
hard problem; the difficulty to conceptualize this specialness, scientists now also speak of the meta-problem; Maybe there’s no fundamentally, inexplicably,
nonphysical essence in us. Maybe our task as scientists is to explain why people tend to believe in a hard problem in the first place. There is a growing number of scientists 
who believe that our idea of consciousness is an illusion 
created within the brain. Whether our brain does this for some functional
reason or if it’s just an accidental consequence of the way we process information is unknown, but what matters most is that from this approach; we wouldn’t have to explain the mystery
of our consciousness, just as we don’t have to explain how the Earth came to be flat, or how the sun orbits around it. They are simply false beliefs, and perhaps our understanding of consciousness is just waiting for its own Copernican revolution. However, as we see Caleb beginning to doubt
the very essence of his own being, we can understand why this idea faces 
heavy resistance. Graziano too warns against labelling consciousness
as an illusion, as it is too often interpreted to mean that consciousness is just a mirage, that there’s nothing behind it, that, as he puts it, consciousness doesn’t exist
and nobody’s home, which also isn’t true. Consciousness is technically similar to a
visual illusion because the information processing that we actually have in our heads is slightly
different from what we claim to have on the basis of introspection, and we make that claim
based on an imperfect internal model – all of which resembles a visual illusion. The point is not that consciousness doesn’t exist, it doesn’t even imply that we humans aren’t special. The point is to show the actual obstacles
in our quest to understand consciousness; obstacles that have little to do with the nature 
of this phenomenon, but instead arise from our limitations 
to properly examine it. And I think it is with this conclusion 
that Ex Machina ends, as the film ultimately reveals less about Ava’s consciousness, than it does about ours. You feel stupid, but you really shouldn’t, because proving an AI is exactly as problematic 
as you said it would be. What was the real test? You. Knowing the obstacles that are in our way, we have a much better chance at understanding consciousness for what it really is, not as a mystical essence unique to humans, but as an evolutionary phenomenon existing in various
forms across various species. 